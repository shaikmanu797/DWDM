k = 3)
?knn
install.packages('knn')
install.packages('magrittr')
iris_pred <- knn(train = iris.training, test = iris.test, cl = iris.trainLabels,
k = 3)
?knn
rm(list=ls())
rm(list=ls())
data(iris)
head(iris)
summary(iris)
require(ggplot2)
ggplot(data = iris) + geom_point(aes(x = Sepal.Length, y = Sepal.Width,
color = Species)) + theme_light()
ggplot(data = iris) + geom_point(aes(x = Petal.Length, y = Petal.Width,
color = Species)) + theme_light()
#install.packages('class')
#install.packages('magrittr')
require(class)
require(magrittr)
summary(iris)
n.iris <- data.frame(sapply(iris[1:4], function(x) {
(x - min(x))/(max(x) - min(x))
}))
head(n.iris)
n.iris[,"Species"] = iris$Species
head(n.iris)
# Split
set.seed(1234) # makes it repeatable
ind <- sample(2, nrow(iris), replace = TRUE, prob = c(0.67, 0.33))
#0.67 - 2/3 data to train 0.33 - 1/3 data to test, never do 50-50 data have one larger one smaller #proportion rule of thumb is 80-20 just check online once
## Data Split
iris.training <- n.iris[ind == 1, 1:4]
iris.test <- n.iris[ind == 2, 1:4]
## Label Split
iris.trainLabels <- n.iris[ind == 1, 5]
iris.testLabels <- n.iris[ind == 2, 5]
#Looking for 3 nearest neighbours
iris_pred <- knn(train = iris.training, test = iris.test, cl = iris.trainLabels,
k = 3)
#looking for 2 nearest neighbours
iris_pred <- knn(train = iris.training, test = iris.test, cl = iris.trainLabels,
k = 2)
#Checking accuracy -- check for above two seperately each time
results = data.frame(iris_pred, iris.testLabels)
table(results)
iris_pred <- knn(train = iris.training, test = iris.test, cl = iris.trainLabels,
k = 3)
results = data.frame(iris_pred, iris.testLabels)
table(results)
iris_pred <- knn(train = iris.training, test = iris.test, cl = iris.trainLabels, k = 3)
results = data.frame(iris_pred, iris.testLabels)
table(results)
rm(list=ls())
data(iris)
head(iris)
summary(iris)
require(ggplot2)
ggplot(data = iris) + geom_point(aes(x = Sepal.Length, y = Sepal.Width,
color = Species)) + theme_light()
ggplot(data = iris) + geom_point(aes(x = Petal.Length, y = Petal.Width,
color = Species)) + theme_light()
#install.packages('class')
#install.packages('magrittr')
require(class)
require(magrittr)
summary(iris)
n.iris <- data.frame(sapply(iris[1:4], function(x) {
(x - min(x))/(max(x) - min(x))
}))
head(n.iris)
n.iris[,"Species"] = iris$Species
head(n.iris)
# Split
set.seed(1234) # makes it repeatable
ind <- sample(2, nrow(iris), replace = TRUE, prob = c(0.67, 0.33))
#0.67 - 2/3 data to train 0.33 - 1/3 data to test, never do 50-50 data have one larger one smaller #proportion rule of thumb is 80-20 just check online once
## Data Split
iris.training <- n.iris[ind == 1, 1:4]
iris.test <- n.iris[ind == 2, 1:4]
## Label Split
iris.trainLabels <- n.iris[ind == 1, 5]
iris.testLabels <- n.iris[ind == 2, 5]
#Looking for 3 nearest neighbours
iris_pred <- knn(train = iris.training, test = iris.test, cl = iris.trainLabels, k = 3)
#looking for 2 nearest neighbours
#iris_pred <- knn(train = iris.training, test = iris.test, cl = iris.trainLabels, k = 2)
#Checking accuracy -- check for above two seperately each time
results = data.frame(iris_pred, iris.testLabels)
table(results)
iris_pred <- knn(train = iris.training, test = iris.test, cl = iris.trainLabels, k = 2)
results = data.frame(iris_pred, iris.testLabels)
table(results)
install.packages('caret')
rm(list = ls())
data(iris)
summary(iris)
n.function <- function(x){
(x-min(x))/(max(x))-min(x))
}
n.function <- function(x){
(x-min(x))/(max(x))-min(x))
}
n.function <- function(x){
(x-min(x))/(max(x))-min(x))
}
n.function <- function(x){
(x-min(x))/(max(x)-min(x))
}
head(iris$Sepal.Length)
n.sepal = n.function(iris$Sepal.Length)
n.irirs<-sapply(iris[1:4], n.function)
head(n.iris)
n.iris<-sapply(iris[1:4], n.function)
head(n.iris)
rm(n.irirs)
head(n.iris)
n.iris <- data.frame(n.iris, iris$Species)
ind = sample(2, nrow(n.iris), replace=T, prob=c(.67,.33))
n.iris.training=n.iris[ind==1,]
n.iris.test = n.iris[ind==2,]
ind
ind
?set.seed
set.seed(234) #Same sample is generated always, instead og getting random samples each time
ind = sample(2, nrow(n.iris), replace=T, prob=c(.67,.33))
ind
set.seed(234) #Same sample is generated always, instead og getting random samples each time
ind = sample(2, nrow(n.iris), replace=T, prob=c(.67,.33))
ind
set.seed(234) #Same sample is generated always, instead og getting random samples each time
ind = sample(2, nrow(n.iris), replace=T, prob=c(.67,.33))
ind
set.seed(234) #Same sample is generated always, instead og getting random samples each time
#234 values means start from that number, this can be any random number
ind = sample(2, nrow(n.iris), replace=T, prob=c(.67,.33))
ind
#splitting data based on rows
n.iris.training = n.iris[ind==1,]
n.iris.test = n.iris[ind==2,]
install.packages(tree)
install.packages('tree')
require('tree')
names(n.iris)
my.model <- tree(iris.Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data=n.iris)
my.model <- tree(iris.Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data = n.iris.training)
my.model <- tree(iris.Species ~ . , data = n.iris.training)
my.model
rm(list = ls())
data(iris)
summary(iris)
#Only numeric datatypes can be normalized. So, choose only those columns from dataframe
n.function <- function(x){
(x-min(x))/(max(x)-min(x))
}
head(iris$Sepal.Length)
n.sepal = n.function(iris$Sepal.Length)
n.iris<-sapply(iris[1:4], n.function)
head(n.iris)
#combine normalized data with species column(category column)
n.iris <- data.frame(n.iris, iris$Species)
set.seed(234) #Same sample is generated always, instead og getting random samples each time
#234 values means start from that number, this can be any random number
ind = sample(2, nrow(n.iris), replace=T, prob=c(.67,.33))
ind
#splitting data based on rows irrespective of column datatype
n.iris.training = n.iris[ind==1,]
n.iris.test = n.iris[ind==2,]
#install.packages('tree')
require('tree')
names(n.iris)
my.model <- tree(iris.Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data = n.iris.training)
# or
my.model <- tree(iris.Species ~ . , data = n.iris.training)
my.model
plot(my.model)
text(my.model, pretty = 0)
my.prediction <- predict(my.model, n.iris.training, type='class')
my.prediction
my.prediction <- predict(my.model, n.iris.test, type='class')
my.prediction
my.prediction
actual = n.iristest$iris.Species
actual = n.iris.test$iris.Species
actual = n.iris.test$iris.Species
actuals = n.iris.test$iris.Species
data.frame(my.prediction, actuals)
which(my.prediction!=actuals)
ErrorPredictions = which(my.prediction!=actuals)
ErrorPredictions
iris[ErrorPredictions,]
results=data.frame(my.prediction, actuals)
table(results)
n.iris.test[ErrorPredictions,]
my.prediction[24]
results[24,]
require(caret)
require(e1071)
confusionMatrix(table(results))
rm(list = ls())
data(iris)
summary(iris)
#Only numeric datatypes can be normalized. So, choose only those columns from dataframe
n.function <- function(x){
(x-min(x))/(max(x)-min(x))
}
head(iris$Sepal.Length)
n.sepal = n.function(iris$Sepal.Length)
n.iris<-sapply(iris[1:4], n.function)
head(n.iris)
#combine normalized data with species column(category column)
n.iris <- data.frame(n.iris, iris$Species)
set.seed(234) #Same sample is generated always, instead og getting random samples each time
#234 values means start from that number, this can be any random number
ind = sample(2, nrow(n.iris), replace=T, prob=c(.67,.33))
ind
#splitting data based on rows irrespective of column datatype
n.iris.training = n.iris[ind==1,]
n.iris.test = n.iris[ind==2,]
#install.packages('tree')
require('tree')
names(n.iris)
my.model <- tree(iris.Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data = n.iris.training)
## or ##
my.model <- tree(iris.Species ~ . , data = n.iris.training)
#my.model
plot(my.model)
text(my.model, pretty = 0)
my.prediction <- predict(my.model, n.iris.test, type='class')
my.prediction
actuals = n.iris.test$iris.Species
results=data.frame(my.prediction, actuals)
table(results)
ErrorPredictions = which(my.prediction!=actuals)
results[24,]
require(caret)
require(e1071)
confusionMatrix(table(results))
cv_tree = cv.tree(my.model, FUN=prune.misclass)
names(cv_tree)
plot(cv_tree$size, cv_tree$dev, type="b")
pruned.model = prune.misclass(my.model, best=3)
plot(pruned.model)
text(pruned.model, pretty=0)
pruned.prediction = predict(pruned.model, iris.test, type = "class")
confusionMatrix(table(pruned.prediction, iris.test$Species))
pruned.prediction = predict(pruned.model, n.iris.test, type = "class")
confusionMatrix(table(pruned.prediction, n.iris.test$Species))
pruned.prediction = predict(pruned.model, n.iris.test, type = "class")
confusionMatrix(table(pruned.prediction, n.iris.test$Species))
confusionMatrix(table(pruned.prediction))
pruned.results = data.frame(pruned.prediction, n.iris.test$iris.Species)
confusionMatrix(table(pruned.results))
confusionMatrix(table(results))
rm(list=ls())
setwd("~/IS665/risk")
classify_risk = read.csv("ClassifyRisk_historical.csv", header=TRUE, sep=",", dec=".")
require(ggplot2)
ggplot(data=classify_risk) + geom_point(aes(x=age, y=income, color=risk)) + theme_light()
summary(classify_risk)
n.function <- function(x){
(x-min(x))/(max(x)-min(x))
}
n.classify_risk<-sapply(classify_risk[, c(2,3,5)], n.function)
head(n.classify_risk)
n.classify_risk <- data.frame(n.classify_risk, classify_risk$risk)
head(n.classify_risk)
set.seed(234)
ind = sample(2, nrow(n.classify_risk), replace=T, prob=c(.67,.33))
ind
n.classify_risk.training = n.classify_risk[ind==1,]
n.classify_risk.test = n.classify_risk[ind==2,]
require('tree')
names(n.classify_risk)
my.model <- tree(classify_risk.risk ~ . , data = n.iris.training)
my.model <- tree(classify_risk.risk ~ . , data = n.classify_risk.training)
plot(my.model)
text(my.model, pretty = 0)
my.prediction <- predict(my.model, n.classify_risk.test, type='class')
my.prediction
actuals = n.classify_risk.test$n.classify_risk.risk
results=data.frame(my.prediction, actuals)
table(results)
actuals = n.classify_risk.test$classify_risk.risk
results=data.frame(my.prediction, actuals)
table(results)
ErrorPredictions = which(my.prediction!=actuals)
ErrorPredictions
require(caret)
require(e1071)
confusionMatrix(table(results))
cv_tree = cv.tree(my.model, FUN=prune.misclass)
names(cv_tree)
plot(cv_tree$size, cv_tree$dev, type="b")
pruned.model = prune.misclass(my.model, best=4)
plot(pruned.model)
text(pruned.model, pretty=0)
pruned.prediction = predict(pruned.model, n.classify_risk.test, type = "class")
pruned.results = data.frame(pruned.prediction, n.classify_risk.test$classify_risk.risk)
confusionMatrix(table(pruned.results))
plot(cv_tree$size, cv_tree$dev, type="b")
pruned.model = prune.misclass(my.model, best=2)
plot(pruned.model)
text(pruned.model, pretty=0)
pruned.prediction = predict(pruned.model, n.classify_risk.test, type = "class")
pruned.results = data.frame(pruned.prediction, n.classify_risk.test$classify_risk.risk)
confusionMatrix(table(pruned.results))
pruned.model = prune.misclass(my.model, best=4)
plot(pruned.model)
text(pruned.model, pretty=0)
pruned.prediction = predict(pruned.model, n.classify_risk.test, type = "class")
pruned.results = data.frame(pruned.prediction, n.classify_risk.test$classify_risk.risk)
confusionMatrix(table(pruned.results))
getwd()
n.classify_risk_test = read.csv("classifyrisk.csv", header=TRUE,
sep=",",dec=".")
classify_risk_test = read.csv("classifyrisk.csv", header=TRUE,
rm(n.classify_risk_test)
)
classify_risk_test = read.csv("classifyrisk.csv", header=TRUE,
sep=",",dec=".")
rm(n.classify_risk_test)
n.classify_risk_test<-sapply(classify_risk_test[, c(2,3,5)], n.function)
head(n.classify_risk)
rm(list=ls())
setwd("~/IS665/risk")
classify_risk = read.csv("ClassifyRisk_historical.csv", header=TRUE, sep=",", dec=".")
require(ggplot2)
ggplot(data=classify_risk) + geom_point(aes(x=age, y=income, color=risk)) + theme_light()
summary(classify_risk)
n.function <- function(x){
(x-min(x))/(max(x)-min(x))
}
n.classify_risk<-sapply(classify_risk[, c(2,3,5)], n.function)
head(n.classify_risk)
n.classify_risk <- data.frame(n.classify_risk, classify_risk$risk)
head(n.classify_risk)
set.seed(234)
ind = sample(2, nrow(n.classify_risk), replace=T, prob=c(.67,.33))
ind
n.classify_risk.training = n.classify_risk[ind==1,]
n.classify_risk.test = n.classify_risk[ind==2,]
#install.packages('tree')
require('tree')
names(n.classify_risk)
my.model <- tree(classify_risk.risk ~ . , data = n.classify_risk.training)
plot(my.model)
text(my.model, pretty = 0)
my.prediction <- predict(my.model, n.classify_risk.test, type='class')
my.prediction
actuals = n.classify_risk.test$classify_risk.risk
results=data.frame(my.prediction, actuals)
table(results)
ErrorPredictions = which(my.prediction!=actuals)
ErrorPredictions
require(caret)
require(e1071)
confusionMatrix(table(results))
cv_tree = cv.tree(my.model, FUN=prune.misclass)
names(cv_tree)
plot(cv_tree$size, cv_tree$dev, type="b")
pruned.model = prune.misclass(my.model, best=4)
plot(pruned.model)
text(pruned.model, pretty=0)
pruned.prediction = predict(pruned.model, n.classify_risk.test, type = "class")
pruned.results = data.frame(pruned.prediction, n.classify_risk.test$classify_risk.risk)
confusionMatrix(table(pruned.results))
classify_risk_test = read.csv("classifyrisk.csv", header=TRUE,
sep=",",dec=".")
n.classify_risk_test<-sapply(classify_risk_test[, c(2,3,5)], n.function)
head(n.classify_risk_test)
pruned.prediction = predict(pruned.model, n.classify_risk_test.test, type = "class")
pruned.prediction = predict(pruned.model, n.classify_risk_test, type = "class")
head(n.classify_risk_test)
rm(list=ls())
setwd("~/IS665/risk")
classify_risk = read.csv("ClassifyRisk_historical.csv", header=TRUE, sep=",", dec=".")
require(ggplot2)
ggplot(data=classify_risk) + geom_point(aes(x=age, y=income, color=risk)) + theme_light()
summary(classify_risk)
n.function <- function(x){
(x-min(x))/(max(x)-min(x))
}
n.classify_risk<-sapply(classify_risk[1:5], n.function)
head(n.classify_risk)
n.classify_risk <- data.frame(n.classify_risk, classify_risk$risk)
head(n.classify_risk)
n.function <- function(x){
(x-min(x))/(max(x)-min(x))
}
n.classify_risk<-sapply(classify_risk[,1:5], n.function)
head(n.classify_risk)
n.classify_risk <- data.frame(n.classify_risk, classify_risk$risk)
head(n.classify_risk)
n.function <- function(x){
(x-min(x))/(max(x)-min(x))
}
n.classify_risk<-sapply(classify_risk[, c(2,3,5)], n.function)
head(n.classify_risk)
n.classify_risk <- data.frame(classify_risk[,1], n.classify_risk[,1:2], classify_risk[,4],
n.classify_risk[,3],classify_risk[,6])
head(n.classify_risk)
colnames(n.classify_risk) <- colnames(classify_risk)
head(n.classify_risk)
set.seed(234)
ind = sample(2, nrow(n.classify_risk), replace=T, prob=c(.67,.33))
ind
n.classify_risk.training = n.classify_risk[ind==1,]
n.classify_risk.test = n.classify_risk[ind==2,]
require('tree')
names(n.classify_risk)
my.model <- tree(risk ~ . , data = n.classify_risk.training)
plot(my.model)
text(my.model, pretty = 0)
my.prediction <- predict(my.model, n.classify_risk.test, type='class')
my.prediction
actuals = n.classify_risk.test$risk
results=data.frame(my.prediction, actuals)
table(results)
ErrorPredictions = which(my.prediction!=actuals)
ErrorPredictions
require(caret)
require(e1071)
confusionMatrix(table(results))
cv_tree = cv.tree(my.model, FUN=prune.misclass)
names(cv_tree)
plot(cv_tree$size, cv_tree$dev, type="b")
pruned.model = prune.misclass(my.model, best=4)
plot(pruned.model)
text(pruned.model, pretty=0)
pruned.prediction = predict(pruned.model, n.classify_risk.test, type = "class")
pruned.results = data.frame(pruned.prediction, n.classify_risk.test$risk)
confusionMatrix(table(pruned.results))
pruned.model = prune.misclass(my.model, best=2)
plot(pruned.model)
text(pruned.model, pretty=0)
pruned.prediction = predict(pruned.model, n.classify_risk.test, type = "class")
pruned.results = data.frame(pruned.prediction, n.classify_risk.test$risk)
confusionMatrix(table(pruned.results))
cv_tree = cv.tree(my.model, FUN=prune.misclass)
names(cv_tree)
plot(cv_tree$size, cv_tree$dev, type="b")
names(n.classify_risk)
n.classify_risk.training
n.classify_risk.test
table(results)
confusionMatrix(table(results))
cv_tree = cv.tree(my.model, FUN=prune.misclass)
names(cv_tree)
plot(cv_tree$size, cv_tree$dev, type="b")
pruned.model = prune.misclass(my.model, best=2)
plot(pruned.model)
text(pruned.model, pretty=0)
pruned.prediction = predict(pruned.model, n.classify_risk.test, type = "class")
pruned.results = data.frame(pruned.prediction, n.classify_risk.test$risk)
confusionMatrix(table(pruned.results))
pruned.model = prune.misclass(my.model, best=4)
plot(pruned.model)
text(pruned.model, pretty=0)
pruned.prediction = predict(pruned.model, n.classify_risk.test, type = "class")
pruned.results = data.frame(pruned.prediction, n.classify_risk.test$risk)
confusionMatrix(table(pruned.results))
plot(cv_tree$size, cv_tree$dev, type="b")
(cv_tree)
pruned.model = prune.misclass(my.model, best=4)
plot(pruned.model)
text(pruned.model, pretty=0)
pruned.prediction = predict(pruned.model, n.classify_risk.test, type = "class")
pruned.results = data.frame(pruned.prediction, n.classify_risk.test$risk)
confusionMatrix(table(pruned.results))
pruned.model = prune.misclass(my.model, best=6)
plot(pruned.model)
text(pruned.model, pretty=0)
pruned.prediction = predict(pruned.model, n.classify_risk.test, type = "class")
pruned.results = data.frame(pruned.prediction, n.classify_risk.test$risk)
confusionMatrix(table(pruned.results))
classify_risk_test = read.csv("classifyrisk.csv", header=TRUE, sep=",", dec=".")
n.classify_risk_test<-sapply(classify_risk_test[, c(2,3,5)], n.function)
head(n.classify_risk_test)
n.classify_risk_test <- data.frame(classify_risk_test[,1],n.classify_risk-test[,1:2],
classify_risk_test[,4],n.classify_risk_test[,3],classify_risk_test[,6])
n.classify_risk_test <- data.frame(classify_risk_test[,1],n.classify_risk-test[,1:2],
classify_risk_test[,4],n.classify_risk_test[,3],classify_risk_test[,6])
n.classify_risk_test <- data.frame(classify_risk_test[,1],n.classify_risk-test[,1:2],
classify_risk_test[,4],n.classify_risk_test[,3],classify_risk_test[,6])
n.classify_risk_test <- data.frame(classify_risk_test[,1],n.classify_risk-test[,1:2],
classify_risk_test[,4], n.classify_risk_test[,3],
classify_risk_test[,6])
n.classify_risk_test <- data.frame(classify_risk_test[,1],n.classify_risk-test[,1:2],
classify_risk_test[,4], n.classify_risk_test[,3],
classify_risk_test[,6])
n.classify_risk_test <- data.frame(classify_risk_test[,1],n.classify_risk_test[,1:2],
classify_risk_test[,4], n.classify_risk_test[,3],
classify_risk_test[,6])
head(n.classify_risk_test)
colnames(n.classify_risk) <- colnames(classify_risk)
head(n.classify_risk_test)
colnames(n.classify_risk_test) <- colnames(classify_risk_test)
head(n.classify_risk_test)
pruned.prediction = predict(pruned.model, n.classify_risk_test.test, type = "class")
pruned.prediction = predict(pruned.model, n.classify_risk_test, type = "class")
pruned.results = data.frame(pruned.prediction, n.classify_risk_test$risk)
confusionMatrix(table(pruned.results))
pruned.prediction = predict(pruned.model, n.classify_risk_test, type = "class")
pruned.prediction
n.classify_risk_test$risk <- pruned.prediction
View(n.classify_risk_test)
